# LLM Provider Configuration
# Get your API keys from the respective provider dashboards:
# - Anthropic: https://console.anthropic.com/
# - OpenAI: https://platform.openai.com/api-keys
# - Google AI: https://aistudio.google.com/app/apikey

# Default LLM Provider (must be 'anthropic' | 'openai' | 'gemini')
# Users can override this per-chat via UI
DEFAULT_LLM_PROVIDER=anthropic

# System API Keys (fallback when user doesn't provide their own)
# At minimum, provide a key for the DEFAULT_LLM_PROVIDER
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
GOOGLE_AI_API_KEY=your_google_ai_api_key_here

# Configuration Storage
# Directory where user configs and encrypted API keys are stored
CONFIG_DIR=./data

# Encryption Secret (32-byte secret for encrypting user API keys)
# Generate with: openssl rand -hex 32
ENCRYPTION_SECRET=your_32_byte_secret_here

# Model Cache Settings
# How long to cache model lists from provider APIs (in seconds)
MODEL_CACHE_TTL=3600

# Server Configuration
PORT=3001
NODE_ENV=development
