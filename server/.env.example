# ============================================================================
# LLM Provider Configuration
# ============================================================================

# Default LLM Provider to use when initializing the application
# Must be one of: 'anthropic' | 'openai' | 'gemini' | 'custom'
# Users can override this per-chat via the UI
# Optional: If not set, users must configure providers via the API/UI
DEFAULT_LLM_PROVIDER=anthropic

# Default API Key for the DEFAULT_LLM_PROVIDER
# Required if DEFAULT_LLM_PROVIDER is set to a standard provider (anthropic, openai, gemini)
# Optional: Users can configure API keys via the API/UI instead
DEFAULT_API_KEY=your_api_key_here

# Default Base URL for custom provider
# Required if DEFAULT_LLM_PROVIDER is set to 'custom'
# Example: https://api.openrouter.ai/v1 or http://localhost:11434/v1 (for Ollama)
# Optional: Only needed when using a custom OpenAI-compatible provider
# DEFAULT_BASE_URL=

# Default Model ID to use
# Optional: Can be set to pre-select a model, or users can select via the UI
DEFAULT_MODEL=

# ============================================================================
# Security Configuration
# ============================================================================

# Secret key for encrypting stored API keys
# Used to encrypt user-provided API keys before storing them in llm-config.json
# Generate a secure 32-byte secret with: openssl rand -hex 32
# Optional: If not set, uses a default development secret (CHANGE IN PRODUCTION!)
API_KEYS_SECRET=your_32_byte_secret_here

# ============================================================================
# Server Configuration
# ============================================================================

# Port number for the Fastify server
# Optional: Defaults to 8000 in dev script, but can be overridden here
PORT=3001

# Node.js environment
# Optional: Standard Node.js environment variable (development, production, test)
NODE_ENV=development

# ============================================================================
# Vercel Deployment (automatically set by Vercel)
# ============================================================================

# VERCEL - Set to "1" when running on Vercel (auto-set by Vercel)
# Used to switch storage to /tmp directory for serverless environment
# VERCEL=1
